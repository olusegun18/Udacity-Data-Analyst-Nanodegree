{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A BRIEF REPORT OF THE DATA WRANGLING PROCESS ON THE WeRateDogs RATINGS DATASET\n",
    "\n",
    "<br> By Joseph Osuntoki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 &emsp;INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project's objective was to gather WeRateDogs Twitter data in order to produce insightful and reliable analysis and visualizations. \n",
    "\n",
    "This project is primarily focused on manipulating data from the WeRateDogs Twitter account using Python. A final notebook (wrangle act.ipynb) was produced after the data wrangling process. \n",
    "\n",
    "The project is the second project of the Udacity Data Analyst Nanodegree program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0   &emsp; PROJECT REQUIREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet history of Twitter user @dog rates, better known as WeRateDogs, is the dataset that used in this project. \n",
    "\n",
    "WeRateDogs is a Twitter account that rates users' dogs and adds a lighthearted comment.\n",
    "\n",
    "It is required in this project that the following objectives are met:\n",
    "+ Gather the data needed\n",
    "+ Assess the data\n",
    "+ Clean the data\n",
    "+ Store the data\n",
    "+ Analyzing and visualizing the data\n",
    "+ Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools and Libraries Needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jupyter notebook is the main tool needed to complete this project. After which, some specific libraries were imported for the data wrangling process. These libraries make the process easier and more efficient.\n",
    "1. pandas - For effective data manipulation\n",
    "2. numpy - For performing arithmetic operations on arrays\n",
    "3. requests - To download a file from the internet programmatically\n",
    "4. json - To read the json file that was queried from Twitter\n",
    "5. matplotlib - For data visualization\n",
    "6. seaborn - An advanced data visualization library\n",
    "7. os - Provides functions for modifying folders and fetching data from them\n",
    "8. tweepy - To query the twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0   &emsp; PROCESS OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different forms of data were used for this project, and they were acquired as described below: \n",
    "\n",
    "* **WeRateDogs Twitter Archive File:** Udacity programmatically extracted this and made twitter archive enhanced.csv available for usage.\n",
    "\n",
    "* **Image Predictions File:** According to a neural network, each tweet's image predicts the breed of dog that is present. The URL https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2adimage-predictions/imagepredictions.tsv was used to programmatically download the file (image predictions.tsv), which was hosted on Udacity's server.\n",
    "\n",
    "* **Twitter API & Tweet JSON File:** Using the tweet IDs from the WeRateDogs Twitter archive, I used Python's tweepy module to query the Twitter API for each tweet's JSON data, and I saved the whole set of JSON data for each tweet in a file called tweet json.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing the Data\n",
    "The three files were assessed both visually and programmatically. Both assessments are useful for detecting data quality issues and data tidiness issues. \n",
    "<br> Data quality issues is mainly concerned completeness, validity, accuracy, and consistency. \n",
    "<br> Data tidiness, on the other hand is concerned with structureal issues that make analysis difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Quality Issues**\n",
    "\n",
    "I discovered the following issues during the wrangling process:\n",
    "1. Repetitive columns: having both retweet_status_id and retweet_status_user_id in the twitter_enhanced dataset creates redundancy. They are not necessary for our analysis\n",
    "\n",
    "2. Incorrect data types in date (twitter_enhanced), all id columns (twitter_enhanced, image, df)\n",
    "\n",
    "3. Incorrect data types in retweet_count and favorite_count in df table (should be integers, not float)\n",
    "\n",
    "4. Standard denominator value (twitter_enhanced) is 10, others should be investigated and corrected\n",
    "\n",
    "5. Missing values in the dog_class (twitter_enhanced)\n",
    "\n",
    "6. Duplicated values in jpg_url column (Image)\n",
    "\n",
    "7. Rating_numrator (twitter_enhanced) - values such as 1776, 666, 960, 420 are high unlikely\n",
    "\n",
    "8. Non-descriptive column names in image table\n",
    "\n",
    "9. Inconsistent format in twitter_enhaned name column (first letter should be in capital letter). Same for first, second, and third predictions in image table\n",
    "\n",
    "10. Iphone seems to be the major source of the data (in twitter_enhanced and df table), the rest cannot be properly interpreted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Tidiness Issues**\n",
    "\n",
    "1. \"doggo\",\"floofer\",\"pupper\",\"puppo\", should be melted into a single column (Twitter_enhanced)\n",
    "\n",
    "2. Source and tweet columns duplicated in twitter_enhanced and df table.\n",
    "\n",
    "3. Created_at (df) - day of the week should be separated from the time of occurrence. Created_at should be dropped as well to prevent date duplication (in tw_enhanced and df)\n",
    "\n",
    "4. Separate date from the hours,minutes in twitter_enhanced\n",
    "\n",
    "5. Let tweet_id be the first column in the df table\n",
    "\n",
    "6. Tweet_id in twitter_enhanced duplicated in the image and df tables\n",
    "\n",
    "7. Tweet_JSON (df) shoud be part of twitter_enhanced. Infact, if possible, all three should be combined into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Data\n",
    "The three datasets were merged together using the merge() function on the \"tweet_id\" column (the only column common to all three) to create a master csv file named twitter_archive_master.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0   &emsp; CONCLUSION\n",
    "A skilled data wrangler is able to gather data from many sources, handle data quality and tidiness issues, and able to transform, manipulate to data to generate insightful findings. I can say, I accomplished the same in this project using all the wonderful Python libraries.\n",
    "I thoroughly enjoyed this project as it drove to me some uncomfortable zones but I went through it all and I'm now proud to say I'm better skilled and equipped to take up a role as a data analyst.\n",
    "<br> Thanks to **ALX** and the **Udacity** team for this opportunity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
